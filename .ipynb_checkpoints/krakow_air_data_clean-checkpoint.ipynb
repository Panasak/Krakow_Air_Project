{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the maximum row display to 500\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the data frame\n",
    "df1 = pd.read_csv('data_sets/january-2017.csv')\n",
    "df2 = pd.read_csv('data_sets/february-2017.csv') \n",
    "df3 = pd.read_csv('data_sets/march-2017.csv')\n",
    "df4 = pd.read_csv('data_sets/april-2017.csv') \n",
    "df5 = pd.read_csv('data_sets/may-2017.csv') \n",
    "df6 = pd.read_csv('data_sets/june-2017.csv') \n",
    "df7 = pd.read_csv('data_sets/july-2017.csv') \n",
    "df8 = pd.read_csv('data_sets/august-2017.csv') \n",
    "df9 = pd.read_csv('data_sets/september-2017.csv') \n",
    "df10 = pd.read_csv('data_sets/october-2017.csv') \n",
    "df11 = pd.read_csv('data_sets/november-2017.csv') \n",
    "df12 = pd.read_csv('data_sets/december-2017.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conbine the dataframe into one year\n",
    "df = pd.concat([df1,df2,df3,df3,df4,df5,df6,df7,df8,df9,df10,df11,df12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that has more more than 10% of the data missing\n",
    "for col in df:\n",
    "    if df[col].isnull().sum() > 933:\n",
    "        df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns with missing data (only take the sensors with temperature,humidity, pressure, pm1, pm25, and pm 10 )\n",
    "# create a list of the first 3 digits of the col names\n",
    "col_front = []\n",
    "for col in df:\n",
    "    col_front.append(col[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which one has missing cols\n",
    "pd.value_counts(col_front) < 6\n",
    "pd.value_counts(col_front).index.tolist()\n",
    "# create a list of all the sensors with missing columns\n",
    "to_del = ['196','183', '176','180','184','177','185','181' '201','179','172','147']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping the to_del from df\n",
    "for col in df:\n",
    "    if col[:3] in to_del:\n",
    "        df.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see which one is the remaining cols\n",
    "pd.value_counts(col_front) == 6\n",
    "pd.value_counts(col_front).index.tolist()\n",
    "# create a list of the remaining cols\n",
    "to_add = ['215','226',\n",
    " '171',\n",
    " '223',\n",
    " '208',\n",
    " '189',\n",
    " '220',\n",
    " '170',\n",
    " '169',\n",
    " '221',\n",
    " '219',\n",
    " '222',\n",
    " '225',\n",
    " '202',\n",
    " '173',\n",
    " '263',\n",
    " '212',\n",
    " '214',\n",
    " '210',\n",
    " '192',\n",
    " '209',\n",
    " '194',\n",
    " '218',\n",
    " '228',\n",
    " '204']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the location to the dataframe\n",
    "#load location data\n",
    "locations =pd.read_csv('data_sets/sensor_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the id to index and make it the columns\n",
    "locations = locations.set_index(keys='id').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = pd.read_csv('data_sets/sensor_locations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = locations.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-526-07cc0f89fa8c>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[f'sensor{num}']['latitude'] = locations.loc[int(num),'latitude']\n",
      "<ipython-input-526-07cc0f89fa8c>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d[f'sensor{num}']['longitude'] = locations.loc[int(num),'longitude']\n"
     ]
    }
   ],
   "source": [
    "# creating a dictionary with all the sensors and times, change the columns to be the same, add latitude & long titude\n",
    "d = {}\n",
    "for num in to_add:\n",
    "    d[f\"sensor{num}\"] = df[['UTC time',f'{num}_temperature',f'{num}_humidity',f'{num}_pressure',f'{num}_pm1',f'{num}_pm25',f'{num}_pm10']]\n",
    "    d[f'sensor{num}'].columns = ['UTC time', 'temperature', 'humidity', 'pressure', 'pm1','pm25', 'pm10']\n",
    "    d[f'sensor{num}']['latitude'] = locations.loc[int(num),'latitude']\n",
    "    d[f'sensor{num}']['longitude'] = locations.loc[int(num),'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the df together to create one long df\n",
    "sensor_d_list = []\n",
    "for num in to_add:\n",
    "    sensor_d_list.append(d[f'sensor{num}'])\n",
    "df_r = pd.concat(sensor_d_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UTC time          0\n",
       "temperature    5102\n",
       "humidity       5144\n",
       "pressure       5343\n",
       "pm1            4738\n",
       "pm25           4723\n",
       "pm10           4721\n",
       "latitude          0\n",
       "longitude         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC time</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>pm1</th>\n",
       "      <th>pm25</th>\n",
       "      <th>pm10</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01T00:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>102212.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>50.096693</td>\n",
       "      <td>19.993572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01T01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>102160.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>50.096693</td>\n",
       "      <td>19.993572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01T02:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>102085.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>50.096693</td>\n",
       "      <td>19.993572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01T03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>102038.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>50.096693</td>\n",
       "      <td>19.993572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01T04:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>101983.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>50.096693</td>\n",
       "      <td>19.993572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2017-12-24T20:00:00</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101728.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>50.062006</td>\n",
       "      <td>19.940984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2017-12-24T21:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101769.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>50.062006</td>\n",
       "      <td>19.940984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>2017-12-24T22:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>101777.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.062006</td>\n",
       "      <td>19.940984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2017-12-24T23:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101778.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>50.062006</td>\n",
       "      <td>19.940984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2017-12-25T00:00:00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>101778.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>50.062006</td>\n",
       "      <td>19.940984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233425 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                UTC time  temperature  humidity  pressure    pm1   pm25  \\\n",
       "0    2017-01-01T00:00:00          2.0      28.0  102212.0   89.0   98.0   \n",
       "1    2017-01-01T01:00:00          1.0      29.0  102160.0   91.0  100.0   \n",
       "2    2017-01-01T02:00:00          1.0      29.0  102085.0  101.0  113.0   \n",
       "3    2017-01-01T03:00:00          1.0      28.0  102038.0  100.0  112.0   \n",
       "4    2017-01-01T04:00:00          1.0      27.0  101983.0   73.0   78.0   \n",
       "..                   ...          ...       ...       ...    ...    ...   \n",
       "572  2017-12-24T20:00:00          7.0      85.0  101728.0    9.0   10.0   \n",
       "573  2017-12-24T21:00:00          6.0      85.0  101769.0    9.0   10.0   \n",
       "574  2017-12-24T22:00:00          6.0      83.0  101777.0    7.0    8.0   \n",
       "575  2017-12-24T23:00:00          6.0      85.0  101778.0    7.0    8.0   \n",
       "576  2017-12-25T00:00:00          6.0      85.0  101778.0    6.0    7.0   \n",
       "\n",
       "      pm10   latitude  longitude  \n",
       "0    156.0  50.096693  19.993572  \n",
       "1    161.0  50.096693  19.993572  \n",
       "2    181.0  50.096693  19.993572  \n",
       "3    178.0  50.096693  19.993572  \n",
       "4    129.0  50.096693  19.993572  \n",
       "..     ...        ...        ...  \n",
       "572   18.0  50.062006  19.940984  \n",
       "573   17.0  50.062006  19.940984  \n",
       "574   14.0  50.062006  19.940984  \n",
       "575   14.0  50.062006  19.940984  \n",
       "576   12.0  50.062006  19.940984  \n",
       "\n",
       "[233425 rows x 9 columns]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill in the remaining columns with average & create dummies variables for lat and long, convert UTC to date time\n",
    "df_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
